---
layout: post
title: Hive执行计划解读
date: 2021-09-30
Author: 娄继涛
categories: 技术组件
tags: [技术组件,HIVE,数仓建设]
comments: true
---

## 一、Hive执行计划解读

**HIVE提供了EXPLAIN命令来展示一个查询的执行计划**,这个执行计划对于我们了解底层原理，hive 调优，排查数据倾斜等很有帮助

使用语法如下：

```
EXPLAIN [EXTENDED|CBO|AST|DEPENDENCY|AUTHORIZATION|LOCKS|VECTORIZATION|ANALYZE] query
```

explain 后面可以跟以下可选参数，注意：这几个可选参数不是 hive 每个版本都支持的

**EXTENDED：**加上 extended 可以输出有关计划的额外信息。这通常是物理信息，例如文件名。这些额外信息对我们用处不大

**CBO：**输出由Calcite优化器生成的计划。CBO 从 hive 4.0.0 版本开始支持

**AST：**输出查询的抽象语法树。AST 在hive 2.1.0 版本删除了，存在bug，转储AST可能会导致OOM错误，将在4.0.0版本修复

**DEPENDENCY**：dependency在EXPLAIN语句中使用会产生有关计划中输入的额外信息。它显示了输入的各种属性

**AUTHORIZATION：**显示所有的实体需要被授权执行（如果存在）的查询和授权失败

**LOCKS：**这对于了解系统将获得哪些锁以运行指定的查询很有用。LOCKS 从 hive 3.2.0 开始支持

**VECTORIZATION：**将详细信息添加到EXPLAIN输出中，以显示为什么未对Map和Reduce进行矢量化。从 Hive 2.3.0 开始支持

**ANALYZE：**用实际的行数注释计划。从 Hive 2.2.0 开始支持



在 hive cli 中输入以下命令(hive 2.3.7)：

```
explain select sum(id) from test1;
```

得到结果：

```
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
 
STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: test1
            Statistics: Num rows: 6 Data size: 75 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: id (type: int)
              outputColumnNames: id
              Statistics: Num rows: 6 Data size: 75 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: sum(id)
                mode: hash
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order:
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint)
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0)
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink
```

**一个HIVE查询被转换为一个由一个或多个stage组成的序列（有向无环图DAG）。这些stage可以是MapReduce stage，也可以是负责元数据存储的stage，也可以是负责文件系统的操作（比如移动和重命名）的stage**。

我们将上述结果拆分看，先从最外层开始，包含两个大的部分：

```
stage dependencies： 各个stage之间的依赖性
stage plan： 各个stage的执行计划
```

先看第一部分 stage dependencies ，包含两个 stage，Stage-1 是根stage，说明这是开始的stage，Stage-0 依赖 Stage-1，Stage-1执行完成后执行Stage-0。

再看第二部分 stage plan，里面有一个 Map Reduce，一个MR的执行计划分为两个部分：

```
Map Operator Tree： MAP端的执行计划树
Reduce Operator Tree： Reduce端的执行计划树
```

这两个执行计划树里面包含这条sql语句的 operator：

1、map端第一个操作肯定是加载表，所以就是 TableScan 表扫描操作，常见的属性：

​		alias： 表名称

​		Statistics： 表统计信息，包含表中数据条数，数据大小等

2、Select Operator： 选取操作，常见的属性 ：

​		expressions：需要的字段名称及字段类型

​		outputColumnNames：输出的列名称

​		Statistics：表统计信息，包含表中数据条数，数据大小等

3、Group By Operator：分组聚合操作，常见的属性：

​		aggregations：显示聚合函数信息

​		mode：聚合模式，值有 hash：随机聚合，就是hash partition；partial：局部聚合；final：最终聚合

​		keys：分组的字段，如果没有分组，则没有此字段

​		outputColumnNames：聚合之后输出列名

​		Statistics： 表统计信息，包含分组聚合之后的数据条数，数据大小等

4、Reduce Output Operator：输出到reduce操作，常见属性：

​		sort order：值为空 不排序；值为 + 正序排序，值为 - 倒序排序；值为 +-  排序的列为两列，第一列为正序，第二列为倒序

5、Filter Operator：过滤操作，常见的属性：

​		predicate：过滤条件，如sql语句中的where id>=1，则此处显示(id >= 1)

6、Map Join Operator：join 操作，常见的属性：

​		condition map：join方式 ，如Inner Join 0 to 1 Left Outer Join0 to 2

​		keys: join 的条件字段

​		outputColumnNames： join 完成之后输出的字段

​		Statistics： join 完成之后生成的数据条数，大小等

7、File Output Operator：文件输出操作，常见的属性

​		compressed：是否压缩

​		table：表的信息，包含输入输出文件格式化方式，序列化方式等

8、Fetch Operator 客户端获取数据操作，常见的属性：

​		limit，值为 -1 表示不限制条数，其他值为限制的条数

好，学到这里再翻到上面 explain 的查询结果，是不是感觉基本都能看懂了。



## **二、HiveSQL优化**



HiveSQL会最终转化为MapReduce进行执行,那么优化的前提是至少对MapReduce有基本的了解

其次是必须了解HiveSQL会转化成怎么样的MapReduce作业(执行计划), 这是优化HiveSQL根本依据.

**切记,HiveSQL的优化本质是对MapReduce作业的优化.**

比如MapReduce的一些特点:

　　数据读取和写入,都是针对HDFS(磁盘)而言,都是**IO操作**

　　不喜欢某一个任务过大(数据倾斜).一个经典的结论:**数据量不是问题,数据倾斜才是**

　　不喜欢大量过小的任务.任务资源申请等本身初始化和管理也是需要消耗时间和资源得.**大量过小任务,导致时间和资源都花在任务维护上了**

所以在HiveSQL上,也是针对这些特点来进行优化

### **一些常见的优化思路**

#### **1. IO**

**只查询需要的列**. MapReduce会根据查询谓词裁剪列,简单说就是不查询的列不读,这样可以降低IO

**尽可能的使用表分区**. 表分区条件后,MapReduce会直接跳过不需要的分区的全部文件,极大的降低IO

#### **2.数据倾斜**

**慎用count(distinct)**    慎用count(distinct)原因是容易造成数据倾斜.因为其执行的MapReduce是以GroupBy分组,再对distinct列排序,然后输出交给Reduce.

​     问题就在这里,相比其它GroupBy聚合统计,count(distinct)少一个关键步骤(Map的预计算,在Map端提前做一次聚合再将聚合结果交给Reduce)

　当Map直接将全部数据交给Reduce后,如果数据的分组本身不平衡(比如及格,80%以上及格数据),会造成某一些Reduce处理太过多的数据,这就是数据倾斜

 count(distinct)可以考虑换GroupBy子查询

 **注意null值带来的数据倾斜** 所有null会认为是同一个值,会走同一个Map,如果null占的比重一大,又是一个数据倾斜.这是业务上考虑是否能做过滤

 这里同样适用其它的业务null值(比如常见的0,1,-1,-99等业务默认值)

####  **3.表关联**

　 **大表放后** MapReduce从后往前构建数据,先过滤大表把数据量降下来,可以在Reduce端的Hash-Join减少数据量,提示效率

  **同列关联** 如可能,用同一列关联 同列关联,无论关联多少表都是一个Map搞定,如果不是同列,就会新开一个MapReduce

#### **4 配置优化**

这里的配置,是指MapReduce或Spark配置

